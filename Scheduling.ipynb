{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El <b>scheduler</b> conocido en espaniol como el <b>planificador</b> es el que se encarga de darle la ilucion al programador de que todos los programas se estan ejecutando al mismo tiempo. La realidad es muy diferente, los programas se ejecutan un <b>slice</b> de tiempo cada uno. Unos con mas priodidad que otros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asi que es el <b>scheduler</b> el que decide cual es el siguiente programa a ejecutar y cual sera el slice de tiempo que le asignara."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turnaround Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation} \n",
    "\\large T_{turnaround} = T_{completion} - T_{arrival}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observacion</b>: Esta es una <b>metrica</b> de <b>performance</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde:\n",
    "- <b>Time completion</b>: Es el tiempo que se tarda en completar la tarea.\n",
    "- <b>Time arrival</b>: Es el tiempo que tarda en arrivar la tarea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tiempo que que tarda una tarea desde que llego hasta que es corrida por el scheduler por primera ves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation} \n",
    "\\large T_{response} = T_{firstrun} - T_{arrival}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde:\n",
    "- <b>Time firstrun</b>: Es el tiempo que en ser corrida por primera ves por el scheduler.\n",
    "- <b>Time arrival</b>: Es el tiempo que tarda en arrivar la tarea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Politicas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First In, First Out (FIFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es la politica mas simple que existe, es simplemente que el scheduler procese los programas por orden de llegada y uno a la ves. Osea que hasta que no termine por completo de ejecutar uno, no siga con el siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un <b>ejemplo</b>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos tres programas el A, el B y el C. Llega primero el A, luego el B, y por ultimo llega el C (pero aproximadamente al mismo tiempo => time arrival es 0 en los 3). Entonces como se ejecutan por orden de llegada pasa lo siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/scheduler_fifo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El A tarda 10 segundos y el B tarda lo que tardo el A mas lo que tardo el B y por ultimo el C tarda lo que tardo el A mas lo que tardo el B mas lo que tardo el C. Entonces el A tardo 10 segundos, el B 20 segundos y el C tardo 30 segundos. Por lo tanto el <b>turnaround time</b> promedio es (10 + 20 + 30) / 3 = 60 / 3 = 20 segundos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso todos los programas tardaron lo mismo en ejecurse, el tema es cuando el que llega primero es el que mas tarda en ejecutarse, ahi surge un problema y es que el <b>turnaround time</b> promedio aumenta mucho porque los siguientes programas tuvieron que esperar que el primero que es el mas tarda, termine. Este es el efecto <b>Convoy</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/sheduler_convoy_effect.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiempo promedio: (100 + 110 + 120) / 3 = 110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest Job First (SJF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta politica se tiene la mejora de que ejecuta los programas en orden de lo que tardan, de menor a mayor. Esto evita el efecto Convoy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/scheduler_shortest_job_first.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>turnaround time</b>: (10 + 20 + 120) / 3 = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, acerquemosnos un poc mas a la realidad, todos los programas no tienen porque llegar al mismo tiempo. Supongamos que primero llega el A en t = 0, y luego llega el B y el C en t = 10. Pasaria lo siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/scheduler_shortest_job_first_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por que el B y el C tarden menos, como el A llego primero lo comenzo a ejecutar y segun esta politica no puede ejecutar un context switch por lo tanto, el <b>time turnaround</b> es:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation} \n",
    "\\large T_{turnaround} = \\frac{(100 - 0) + (110 - 10) + (120 - 10)}{3} = 103.3\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es bastante, asi que vamos a tener que seguir implentando mejoras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest Time-To-Completion First (STCF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta politica habilita el uso del <b>context switch</b>. Sigamos con el ejemplo anterior para verlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/scheduler_shortest_job_first_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tareas llegan en el mismo orden y tiempo que el ejemplo anterior. Entonces comienza a ejecutar la tarea A, luego llegan la B y la C. Como esta politica tiene la habilidad de hacer context switch, y le interesa dar al usuario un mejor <b>response time</b> va a correr la tarea B y luego la C que tienen menor <b>time to completion</b> es decir son tareas mas cortas. Veamos como mejora el <b>time turnaround</b>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation} \n",
    "\\large T_{turnaround} = \\frac{(120 - 0) + (20 - 10) + (30 - 10)}{3} = 50\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round Robin (RR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta politica introduce una significativa mejora en el <b>response time</b>. Ya que no espera a ejecutar una tarea por completo para pasar a la siguiente, sino que ejecuta un cachito de tiempo cada tarea, esto hace que el usuario valla teniendo feedback. A este cachito de tiempo se le llama <b>time slice</b>, tambien conocido como <b>scheduling quantum</b>. Por esta razon es que a Round Robin a veces se le llama <b>Time Slicing</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/scheduler_round_robin.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos con un <b>ejemplo</b> como mejora el <b>response time</b>. Supongamos que tenemos 3 tareas, A, B, C, todas llegan al mismo tiempo, cada una tarda en completarse 5 segundos (ver figura de arriba). Si usamos la politica SJF el <b>response time</b> es [(0 - 0) + (5 - 0) + (10 - 0)] / 3 = 5, ahora bien si usamos la politica <b>RR</b> el <b>response time</b> es (0 + 1 + 2) / 3 = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien el <b>response time</b> siempre mejora, el <b>turnaround time</b> en muchos casos seguramente aumente, osea empeore debido que los <b>context switch</b> tienen un costo temporal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asi que no se deben hacer demasiado pequenios los <b>time slice</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generalizar un poco la cuestion hasta aca, tenemos dos tipos de politicas las que mejoran el <b>time turnaround</b> que son <b>SJF</b> y <b>STCF</b> y las que mejoran el <b>time response</b> que es <b>RR</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating I / O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a poner a poner las cosas de forma todabia mas realista, vamos a tener en cuenta que los programas tienen INPUT y OUTPUT. Esto cambia un poco las cosas por el lado de que cuando tienen que escribir o leer de algun periferico demoran mas tiempo de que si operan simplemente con RAM o los registros de procesador. Esto hace que por ejemplo si un programa tiene que leer de disco, el CPU se quede esperando hasta que el programa termine de leer. Y por lo tanto el CPU se quede sin hacer nada ese tiempo. Veamos esto con el siguiente esquema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/scheduler_poor_use_of_resources.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asi que la solucion a esto es que el procesador en el tiempo que esta esperando algo de I/O. No se quede esperando sino que siga ejecutando otro tarea, es decir, aprobechando el tiempo al maximo, esto se ve en el siguiente esquema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/scheduler_overlap.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Multi-Level Feedback Queue (MLFQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este algoritmo o politica de Scheduling fue descrito por <b>Corbato</b> en 1962 y fue ganador del gran premio <b>Turing Award</b>. Este tiene la meta de optimizar el <b>turnaround time</b> como lo hace <b>SJF</b> y <b>SCTF</b>, pero teniendo en encuenta la realidad, y es que no se conoce que van a hacer los procesos, como para determinar cual es el mas corto. Y tambien tiene la meta de optimizar el <b>response time</b> como lo hace <b>RR</b>, para que los usuarios puedan interactuar con la pc de forma placentera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La gran pregunta es entonces: <b>De que manera hacer schedule sin el perfecto conocimiento de los procesos?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MLFQ</b> es un sistema que aprende del pasado para predecir el futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como su nombre lo indica este algoritmo trabaja con <b>colas</b>, con varias, a las que a cada una le asigna una <b>prioridad</b>. Asi que, estas colas estan <b>ordenadas</b> por prioridad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las <b>reglas</b> que cumplen las tareas en este algoritmo son:\n",
    "- <b>Rule 1</b>: Si Prioridad(A) > Prioridad(B), A corre (B no)\n",
    "- <b>Rule 2</b>: Si Prioridad(A) = Prioridad(B), A y B corren en RR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente figura A y B son las tareas con mayor prioridad, C tiene prioridad media y D tiene prioridad baja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/scheduler_MLFQ.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo a decir es que todas las tareas comienzan con la <b>mejor prioridad</b>, luego el algoritmo va aprendiendo sobre la tarea y va a decidir de mantener la prioridad o bajarla. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora estudiemos como MLFQ realiza los cambios de prioridad. Este algoritmo dice lo siguiente, si cuando le damos un <b>time slice</b> a una tarea, esta tarea utiliza completamente el time slice, entonces quiere decir que es una tarea de procesamiento, es decir no es una tarea en la que importe el response time, por lo tanto a esta le bajamos su prioridad. En cambio si la tarea no utiliza por completo el time slice, entonces muy probablemente esta tarea si que importe el reponse time y por lo tanto mantendremos su prioridad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasemoslo formalmente a las siguientes tres reglas mas:\n",
    "- <b>Rule 3</b>: Cuando una tarea entra al sistema, es puesta en la mas alta prioridad.\n",
    "- <b>Rule 4</b>: Si la tarea usa el time slice entero entonces su prioridad es reducida, baja un lugar hacia una cola de menor prioridad.\n",
    "- <b>Rule 5</b>: Si una tarea usa menos del time slice entero entonces su prioridad se mantiene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora un <b>ejemplo</b> de que es lo que pasa con una tarea que requiere mucho procesamiento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/scheduler_MLFQ_long_running.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos como el primer time slice lo ejecuta en la cola de mas alta prioridad pero como lo utiliza todo desciende un nivel en la cola, luego lo mismo, consume todo el time slice, entonces vuelve a bajar un nivel. Hasta que termina en la cola de peor prioridad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos otro <b>ejemplo</b> ahora de dos tareas A y B. A comienza primero y hace uso intensivo del CPU entonces baja de prioridad, luego llega B y se termina de correr en dos time slices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/scheduler_MLFQ_example_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar en Q0 como los dos time slices siguientes al 100 no los tiene el proceso A que es el negro sino que los tiene el proceso B que es el gris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos un <b>ejemplo</b> mas de lo que sucede cuando la tarea no utiliza por completo el time slice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/scheduler_MLFQ_example_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tarea gris no utiliza nunca por completo el time slice debido a que requiere de I/O. Pero cuando llega a necesitar procesamiento de la CPU ver como se lo saca a la tarea negra, la que esta en Q0, esto es porque la tarea gris tiene mas prioridad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
